{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4UyCfhXqAF-"
   },
   "source": [
    "Instalaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "JJqYYC8iqAuI",
    "outputId": "413eed8e-f015-4f72-ce4f-86285c99e27a"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nm0jvfz1p47Z"
   },
   "source": [
    "imports utilizados en el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOvgLGqKpfBz",
    "outputId": "b62edea6-adea-4776-b935-9c9f52ff5a22"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "\n",
    "# Montar Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZJ3nTQgqIKM"
   },
   "source": [
    "Funciones a usar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBPR9LpEqJX9"
   },
   "outputs": [],
   "source": [
    "def leer_datos(carpeta, index):\n",
    "    # Definir ruta base\n",
    "    ruta_base = '/content/drive/MyDrive/lab5micros/datos'\n",
    "    ruta_carpeta = os.path.join(ruta_base, carpeta)\n",
    "    input = []\n",
    "    output= []\n",
    "\n",
    "    # Verificar si el directorio existe\n",
    "    if not os.path.isdir(ruta_carpeta):\n",
    "        print(f\"La carpeta '{ruta_carpeta}' no existe.\")\n",
    "        return input, output\n",
    "\n",
    "    # Iterar los archivos CSV de un directorio\n",
    "    for archivo in os.listdir(ruta_carpeta):\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "            with open(ruta_archivo, 'r') as f:\n",
    "                lector = csv.reader(f)\n",
    "                datos_archivo = list(lector)[1:101]  # Omitir header\n",
    "                input.append(datos_archivo)\n",
    "                # Agregar el output correspondiente\n",
    "                output.append([1 if i == index else 0 for i in range(3)])\n",
    "\n",
    "    return input, output\n",
    "\n",
    "def preparar_datos():\n",
    "    # Inicializar semillas para reproducir resultados\n",
    "    SEED = 5496\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    # Directorios a usar\n",
    "    carpetas = ['arriba', 'jalar', 'revés', 'quieto', 'lento']\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    # Leer datos de cada directorio\n",
    "    for i, carpeta in enumerate(carpetas):\n",
    "        matriz_datos, identificador_archivos = leer_datos(carpeta, i)\n",
    "        inputs.extend(matriz_datos)\n",
    "        outputs.extend(identificador_archivos)\n",
    "\n",
    "    # Normalizar datos\n",
    "    num_max = max([max([max([abs(float(data)) for data in point])] for point in input) for input in inputs])[0]\n",
    "    for i in range(len(inputs)):\n",
    "      for j in range(len(inputs[i])):\n",
    "        for k in range(len(inputs[i][j])):\n",
    "          inputs[i][j][k] = (float(inputs[i][j][k])+ num_max/2)/(2*num_max)\n",
    "\n",
    "    inputs = [[data for point in input for data in point] for input in inputs]\n",
    "\n",
    "    # Convertir a np array\n",
    "    inputs = np.array(inputs, dtype=float)\n",
    "    outputs = np.array(outputs, dtype=float)\n",
    "\n",
    "    #Shuffle\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    inputs = inputs[indices]\n",
    "    outputs = outputs[indices]\n",
    "\n",
    "    # Dividir datos: 60% entrenar, 20% validación, 20% pruebas\n",
    "    num_entrenamiento = int(0.6 * len(inputs))\n",
    "    num_validacion = int(0.2 * len(inputs))\n",
    "\n",
    "    x_train, y_train = inputs[:num_entrenamiento], outputs[:num_entrenamiento]\n",
    "    x_val, y_val = inputs[num_entrenamiento:num_entrenamiento + num_validacion], outputs[num_entrenamiento:num_entrenamiento + num_validacion]\n",
    "    x_test, y_test = inputs[num_entrenamiento + num_validacion:], outputs[num_entrenamiento + num_validacion:]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test\n",
    "\n",
    "def crear_modelo():\n",
    "    modelo = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  # Three outputs for the three types of movement\n",
    "    ])\n",
    "\n",
    "    modelo.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta sección corresponde al código usado para generar archivos de dtos donde el movimiento inicia em movimientos varios de la lectura de datos, solamente se corre una vez puesto que cambia el contenido de las carpetas agregando archivos csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "carpetas = ['arriba', 'jalar', 'revés']\n",
    "quieto = 'quieto'\n",
    "\n",
    "def get_random_quieto():\n",
    "    # Definir ruta base\n",
    "    ruta_base = '/content/drive/MyDrive/lab5micros/datos'\n",
    "    ruta_carpeta = os.path.join(ruta_base, carpeta)\n",
    "    input = []\n",
    "    output= []\n",
    "\n",
    "    # Revisar si directorio existe\n",
    "    if not os.path.isdir(ruta_carpeta):\n",
    "        print(f\"La carpeta '{ruta_carpeta}' no existe.\")\n",
    "        return input, output\n",
    "\n",
    "    # Obtener todos los csv en el directorio\n",
    "    archivos_csv = [archivo for archivo in os.listdir(ruta_carpeta) if archivo.endswith('.csv')]\n",
    "\n",
    "    # En caso de no tener archivos csv\n",
    "    if not archivos_csv:\n",
    "        print(f\"No hay archivos CSV en la carpeta '{ruta_carpeta}'.\")\n",
    "        return input, output\n",
    "\n",
    "    # Seleccionar un archivo csv aleatorio\n",
    "    archivo_aleatorio = random.choice(archivos_csv)\n",
    "    ruta_archivo = os.path.join(ruta_carpeta, archivo_aleatorio)\n",
    "    # Leer el csv\n",
    "    with open(ruta_archivo, 'r') as f:\n",
    "        lector = csv.reader(f)\n",
    "        datos_archivo = list(lector)[1:101]  # Omitir encabezado\n",
    "        return datos_archivo\n",
    "\n",
    "\n",
    "# Duplicar archivos en todas las carpetas\n",
    "for i, carpeta in enumerate(carpetas):\n",
    "    # Set base path to Google Drive folder\n",
    "    ruta_base = '/content/drive/MyDrive/lab5micros/datos'\n",
    "    ruta_carpeta = os.path.join(ruta_base, carpeta)\n",
    "\n",
    "    input_data = []\n",
    "    output_data = []\n",
    "\n",
    "    # Iterar sobre los csv\n",
    "    for archivo in os.listdir(ruta_carpeta):\n",
    "        if archivo.endswith('.csv'):\n",
    "            ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "            with open(ruta_archivo, 'r') as f:\n",
    "                lector = csv.reader(f)\n",
    "                datos_archivo = list(lector)\n",
    "\n",
    "                # Dupilcar datos\n",
    "                header = datos_archivo[0] \n",
    "                datos_sin_encabezado = datos_archivo[1:101]\n",
    "\n",
    "                for dup in range(6):\n",
    "                  datos_quieto  = get_random_quieto()\n",
    "                  datos_quieto[1:101]\n",
    "\n",
    "                  # Indice inicial aleatorio\n",
    "                  random_index = random.randint(0, len(datos_archivo) - 1)\n",
    "\n",
    "                  # Crear nueva lista\n",
    "                  datos_combinados = []\n",
    "                  # Decide si inica quieto o en un movimiento\n",
    "                  use_quieto_first = random.choice([True, False])\n",
    "\n",
    "                  if use_quieto_first:\n",
    "                    # Llenar con quieto y luego agregar movimiento\n",
    "                    print(datos_quieto)\n",
    "                    print(datos_sin_encabezado)\n",
    "                    datos_combinados.extend(datos_quieto[:random_index])\n",
    "                    datos_combinados.extend(datos_sin_encabezado[random_index:])\n",
    "                    print(datos_combinados)\n",
    "                  else:\n",
    "                    # Llenar con movimiento y agregar quieto\n",
    "                    datos_combinados.extend(datos_sin_encabezado[:random_index])\n",
    "                    datos_combinados.extend(datos_quieto[random_index:])\n",
    "\n",
    "\n",
    "                  # Crear archivo nuevo\n",
    "                  nuevo_nombre_archivo = archivo.replace('.csv', f'_dup{dup}.csv')\n",
    "                  ruta_nuevo_archivo = os.path.join(ruta_carpeta, nuevo_nombre_archivo)\n",
    "\n",
    "                  # Llenar el archivo nuevo\n",
    "                  with open(ruta_nuevo_archivo, 'w', newline='') as f_nuevo:\n",
    "                      escritor = csv.writer(f_nuevo)\n",
    "                      escritor.writerow(header)  \n",
    "                      escritor.writerows(datos_combinados)  \n",
    "\n",
    "                  print(f\"Archivo duplicado guardado como: {nuevo_nombre_archivo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGpK8qLgqO9p"
   },
   "source": [
    "Ejecutar el código, cumple la función de un main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "UdYSTz_zqPcU",
    "outputId": "cb1b6b47-29b2-4b46-b267-0e13aad2bb87"
   },
   "outputs": [],
   "source": [
    "from re import X\n",
    "# Prepare data\n",
    "input_train, output_train, input_val, output_val, input_test, output_test = preparar_datos()\n",
    "\n",
    "model = crear_modelo()\n",
    "model.fit(input_train, output_train, epochs=100, validation_data=(input_val, output_val))\n",
    "test_loss, test_acc = model.evaluate(input_test, output_test)\n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "\n",
    "# Obtener predicciones y calcular la matriz de confusión\n",
    "y_prediction = model.predict(input_test)\n",
    "y_prediction = np.argmax(y_prediction, axis=1)\n",
    "y_test = np.argmax(output_test, axis=1)\n",
    "\n",
    "# Crear matriz de confusión y normalizar por columnas\n",
    "conf_matrix = tf.math.confusion_matrix(y_test, y_prediction)\n",
    "conf_matrix = tf.cast(conf_matrix, dtype=tf.float32)\n",
    "conf_matrix_normalized = conf_matrix / tf.reduce_sum(conf_matrix, axis=0)\n",
    "\n",
    "# Imprimir la matriz de confusión normalizada\n",
    "print(\"Matriz de Confusión Normalizada:\\n\", conf_matrix_normalized)\n",
    "\n",
    "\n",
    "# Convert model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open('/content/drive/MyDrive/modelo_movimiento.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"Model saved as 'modelo_movimiento.tflite' in Google Drive\")\n",
    "print(input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasar el modelo entrenado de .tflite a .h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "im07Qedww2FD",
    "outputId": "74043ec5-824a-48a6-ae40-76cccb223e13"
   },
   "outputs": [],
   "source": [
    "!echo \"const unsigned char model[] = {\" > /content/drive/MyDrive/model.h\n",
    "!cat /content/drive/MyDrive/modelo_movimiento.tflite | xxd -i      >> /content/drive/MyDrive/model.h\n",
    "!echo \"};\"                              >> /content/drive/MyDrive/model.h\n",
    "\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTNhHkk2w1rh"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
